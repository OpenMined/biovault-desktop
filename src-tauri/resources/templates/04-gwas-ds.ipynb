{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Beaver Tutorial 4: GWAS Analysis (Data Scientist)\n",
    "\n",
    "This tutorial demonstrates running a **Genome-Wide Association Study (GWAS)** pipeline using PLINK with privacy-preserving collaboration.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **You (Data Scientist)**: Define the GWAS analysis pipeline\n",
    "- **Data Owner**: Provides real genomic data and runs PLINK on their machine\n",
    "- **Results**: You receive Manhattan plots, QQ plots, and significant SNPs (not raw genotypes)\n",
    "\n",
    "## How to Run This Tutorial\n",
    "\n",
    "### Option 1: Two Browser Tabs (Solo Testing)\n",
    "1. Create a session with yourself in BioVault\n",
    "2. Open two Jupyter tabs from the same session\n",
    "3. Run the DO notebook in one tab, this notebook in the other\n",
    "\n",
    "### Option 2: With a Collaborator\n",
    "1. Create a session with your collaborator\n",
    "2. They run the DO notebook, you run this DS notebook\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install pandas numpy matplotlib -q\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import beaver\n",
    "from beaver import Twin\n",
    "import time\n",
    "\n",
    "bv = beaver.ctx()\n",
    "session = bv.active_session()\n",
    "\n",
    "print(f\"You are: {bv.user}\")\n",
    "print(f\"Session peer: {session.peer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wait-data-header",
   "metadata": {},
   "source": [
    "## Step 2: Wait for GWAS Data from DO\n",
    "\n",
    "**Run DO notebook Steps 1-4 first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for DO to publish 'gwas_data'...\")\n",
    "\n",
    "gwas_data = None\n",
    "for _ in range(120):  # Wait up to 2 minutes\n",
    "    peer_vars = session.peer_remote_vars\n",
    "    if \"gwas_data\" in peer_vars:\n",
    "        gwas_data = peer_vars[\"gwas_data\"].load(inject=False, auto_accept=True)\n",
    "        print(f\"\\nLoaded GWAS data info from {session.peer}!\")\n",
    "        break\n",
    "    time.sleep(1)\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "\n",
    "if gwas_data is None:\n",
    "    print(\"\\nTimeout! Make sure DO has run Steps 1-4.\")\n",
    "else:\n",
    "    display(gwas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the mock data info (what we can see)\n",
    "if gwas_data:\n",
    "    mock = gwas_data.public\n",
    "    print(\"Mock Dataset Info (safe to preview):\")\n",
    "    print(f\"  Dataset 1: {mock['dataset1_name']}\")\n",
    "    print(f\"    Samples: {mock['n_samples_1']}\")\n",
    "    print(f\"    Variants: {mock['n_variants_1']}\")\n",
    "    print(f\"  Dataset 2: {mock['dataset2_name']}\")\n",
    "    print(f\"    Samples: {mock['n_samples_2']}\")\n",
    "    print(f\"    Variants: {mock['n_variants_2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-header",
   "metadata": {},
   "source": [
    "## Step 3: Define the GWAS Pipeline Function\n",
    "\n",
    "This function will be sent to the DO for execution on their private data.\n",
    "It uses PLINK (which must be installed on the DO's machine) to:\n",
    "1. Merge datasets\n",
    "2. Run PCA for population stratification\n",
    "3. Perform association testing\n",
    "4. Generate Manhattan and QQ plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bv\n",
    "def run_gwas_pipeline(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Run a complete GWAS pipeline using PLINK.\n",
    "    \n",
    "    Steps:\n",
    "    1. Merge two datasets\n",
    "    2. Run PCA for population stratification\n",
    "    3. Perform logistic regression with PCA covariates\n",
    "    4. Generate Manhattan and QQ plots\n",
    "    \n",
    "    Returns summary statistics (not raw genotypes).\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"GWAS ANALYSIS PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Extract dataset info\n",
    "    DATASET1 = data['dataset1_prefix']\n",
    "    DATASET2 = data['dataset2_prefix']\n",
    "    \n",
    "    print(f\"Dataset 1: {data['dataset1_name']}\")\n",
    "    print(f\"Dataset 2: {data['dataset2_name']}\")\n",
    "    \n",
    "    # Create work directory\n",
    "    WORKDIR = Path(tempfile.mkdtemp(prefix=\"gwas_\"))\n",
    "    COMBINED = WORKDIR / \"combined_qc\"\n",
    "    LOGS_DIR = WORKDIR / \"logs\"\n",
    "    LOGS_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Parameters\n",
    "    N_PCS = 10\n",
    "    THREADS = 4\n",
    "    PLINK = \"plink\"\n",
    "    ANNOTATION_PVAL = 1e-5\n",
    "    GW_SIG = 5e-8\n",
    "    \n",
    "    def run_plink(args, log_name):\n",
    "        \"\"\"Run PLINK with logging.\"\"\"\n",
    "        cmd = [PLINK] + args\n",
    "        log_path = LOGS_DIR / f\"{log_name}.log\"\n",
    "        print(f\"\\n>> {' '.join(cmd[:6])}...\")\n",
    "        \n",
    "        with log_path.open(\"w\") as log_file:\n",
    "            proc = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "            )\n",
    "            for line in proc.stdout:\n",
    "                log_file.write(line)\n",
    "            ret = proc.wait()\n",
    "        \n",
    "        if ret != 0:\n",
    "            raise subprocess.CalledProcessError(ret, cmd)\n",
    "        return ret\n",
    "    \n",
    "    def count_samples_and_cases(fam_path):\n",
    "        \"\"\"Count samples, cases, controls from FAM file.\"\"\"\n",
    "        total, cases, controls = 0, 0, 0\n",
    "        with open(fam_path) as f:\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                total += 1\n",
    "                fields = line.split()\n",
    "                if len(fields) >= 6:\n",
    "                    pheno = fields[5]\n",
    "                    if pheno == \"2\":\n",
    "                        cases += 1\n",
    "                    elif pheno == \"1\":\n",
    "                        controls += 1\n",
    "        return total, cases, controls\n",
    "    \n",
    "    def count_snps(bim_path):\n",
    "        \"\"\"Count SNPs from BIM file.\"\"\"\n",
    "        count = 0\n",
    "        with open(bim_path) as f:\n",
    "            for _ in f:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    # ================================================================\n",
    "    # STEP 1: MERGE DATASETS\n",
    "    # ================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 1: Merging datasets\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        run_plink(\n",
    "            [\"--bfile\", DATASET1, \"--bmerge\", DATASET2, \"--out\", str(COMBINED)],\n",
    "            log_name=\"merge\",\n",
    "        )\n",
    "    except subprocess.CalledProcessError:\n",
    "        # Handle strand issues\n",
    "        missnp_path = Path(f\"{COMBINED}-merge.missnp\")\n",
    "        if missnp_path.exists():\n",
    "            print(\"Found strand issues, flipping and re-merging...\")\n",
    "            flipped = f\"{DATASET2}_flipped\"\n",
    "            run_plink(\n",
    "                [\"--bfile\", DATASET2, \"--flip\", str(missnp_path), \"--make-bed\", \"--out\", flipped],\n",
    "                log_name=\"flip\",\n",
    "            )\n",
    "            run_plink(\n",
    "                [\"--bfile\", DATASET1, \"--bmerge\", flipped, \"--out\", str(COMBINED)],\n",
    "                log_name=\"merge_retry\",\n",
    "            )\n",
    "    \n",
    "    print(\"Datasets merged successfully!\")\n",
    "    \n",
    "    # Get sample counts\n",
    "    fam_path = Path(f\"{COMBINED}.fam\")\n",
    "    total_samples, cases, controls = count_samples_and_cases(fam_path)\n",
    "    total_snps = count_snps(Path(f\"{COMBINED}.bim\"))\n",
    "    \n",
    "    print(f\"Combined: {total_samples} samples, {total_snps} SNPs\")\n",
    "    print(f\"Cases: {cases}, Controls: {controls}\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # STEP 2: PCA FOR POPULATION STRATIFICATION\n",
    "    # ================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2: PCA for population stratification\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # LD pruning\n",
    "    print(\"LD pruning...\")\n",
    "    run_plink(\n",
    "        [\"--bfile\", str(COMBINED), \"--indep-pairwise\", \"50\", \"5\", \"0.2\", \"--out\", f\"{COMBINED}_pruned\"],\n",
    "        log_name=\"ld_prune\",\n",
    "    )\n",
    "    \n",
    "    # Extract pruned SNPs\n",
    "    run_plink(\n",
    "        [\"--bfile\", str(COMBINED), \"--extract\", f\"{COMBINED}_pruned.prune.in\", \"--make-bed\", \"--out\", f\"{COMBINED}_pruned_data\"],\n",
    "        log_name=\"extract_pruned\",\n",
    "    )\n",
    "    \n",
    "    # Remove AT/GC SNPs\n",
    "    atgc_snps = WORKDIR / \"atgc_snps.txt\"\n",
    "    with open(f\"{COMBINED}_pruned_data.bim\") as infile, open(atgc_snps, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            fields = line.strip().split()\n",
    "            if len(fields) >= 6:\n",
    "                rsid, a1, a2 = fields[1], fields[4], fields[5]\n",
    "                if (a1, a2) in [(\"A\", \"T\"), (\"T\", \"A\"), (\"C\", \"G\"), (\"G\", \"C\")]:\n",
    "                    outfile.write(rsid + \"\\n\")\n",
    "    \n",
    "    run_plink(\n",
    "        [\"--bfile\", f\"{COMBINED}_pruned_data\", \"--exclude\", str(atgc_snps), \"--make-bed\", \"--out\", f\"{COMBINED}_pruned_noambig\"],\n",
    "        log_name=\"remove_ambig\",\n",
    "    )\n",
    "    \n",
    "    # Run PCA\n",
    "    print(f\"Computing {N_PCS} principal components...\")\n",
    "    run_plink(\n",
    "        [\"--bfile\", f\"{COMBINED}_pruned_noambig\", \"--pca\", str(N_PCS), \"--threads\", str(THREADS), \"--out\", f\"{COMBINED}_pca\"],\n",
    "        log_name=\"pca\",\n",
    "    )\n",
    "    \n",
    "    # Add header to eigenvec\n",
    "    eigenvec_path = Path(f\"{COMBINED}_pca.eigenvec\")\n",
    "    header = \" \".join([\"FID\", \"IID\"] + [f\"PC{i}\" for i in range(1, N_PCS + 1)]) + \"\\n\"\n",
    "    content = eigenvec_path.read_text()\n",
    "    eigenvec_path.write_text(header + content)\n",
    "    \n",
    "    print(\"PCA complete!\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # STEP 3: ASSOCIATION TESTING\n",
    "    # ================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 3: Association testing\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    covar_names = \",\".join([f\"PC{i}\" for i in range(1, N_PCS + 1)])\n",
    "    \n",
    "    print(\"Running logistic regression...\")\n",
    "    run_plink(\n",
    "        [\"--bfile\", str(COMBINED), \"--logistic\", \"hide-covar\", \"--covar\", str(eigenvec_path),\n",
    "         \"--covar-name\", covar_names, \"--ci\", \"0.95\", \"--threads\", str(THREADS), \"--out\", f\"{COMBINED}_gwas\"],\n",
    "        log_name=\"gwas\",\n",
    "    )\n",
    "    print(\"Association testing complete!\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # STEP 4: GENERATE PLOTS\n",
    "    # ================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 4: Generating plots\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load results\n",
    "    gwas_results = f\"{COMBINED}_gwas.assoc.logistic\"\n",
    "    df = pd.read_csv(gwas_results, sep=r\"\\s+\")\n",
    "    \n",
    "    # Clean P values\n",
    "    df = df[df['P'].notna()]\n",
    "    df = df[df['P'] != 'NA']\n",
    "    df['P'] = pd.to_numeric(df['P'], errors='coerce')\n",
    "    df = df.dropna(subset=['P'])\n",
    "    df = df[(df['P'] > 0) & (df['P'] <= 1)]\n",
    "    \n",
    "    # Calculate -log10(p)\n",
    "    df['NEGLOG10P'] = -np.log10(df['P'])\n",
    "    df = df[np.isfinite(df['NEGLOG10P'])]\n",
    "    \n",
    "    # Convert CHR to numeric\n",
    "    df['CHR'] = df['CHR'].replace({'X': 23, 'Y': 24, 'MT': 25, 'M': 25})\n",
    "    df['CHR'] = pd.to_numeric(df['CHR'], errors='coerce')\n",
    "    df = df.dropna(subset=['CHR', 'BP'])\n",
    "    df['CHR'] = df['CHR'].astype(int)\n",
    "    df['BP'] = df['BP'].astype(int)\n",
    "    \n",
    "    print(f\"Loaded {len(df):,} SNPs\")\n",
    "    \n",
    "    # Count significant\n",
    "    gw_significant = df[df['P'] < GW_SIG]\n",
    "    suggestive = df[df['P'] < ANNOTATION_PVAL]\n",
    "    \n",
    "    print(f\"Genome-wide significant (P < {GW_SIG}): {len(gw_significant)}\")\n",
    "    print(f\"Suggestive (P < {ANNOTATION_PVAL}): {len(suggestive)}\")\n",
    "    \n",
    "    # --- Manhattan Plot ---\n",
    "    print(\"\\nGenerating Manhattan plot...\")\n",
    "    df = df.sort_values(['CHR', 'BP']).reset_index(drop=True)\n",
    "    \n",
    "    df['cumulative_pos'] = 0\n",
    "    chr_centers = []\n",
    "    last_pos = 0\n",
    "    \n",
    "    for chrom in sorted(df['CHR'].unique()):\n",
    "        chr_df = df[df['CHR'] == chrom]\n",
    "        chr_len = chr_df['BP'].max()\n",
    "        df.loc[df['CHR'] == chrom, 'cumulative_pos'] = chr_df['BP'] + last_pos\n",
    "        chr_centers.append(last_pos + chr_len / 2)\n",
    "        last_pos += chr_len\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    colors = ['#3182bd', '#9ecae1']\n",
    "    chr_list = sorted(df['CHR'].unique())\n",
    "    \n",
    "    for idx, chrom in enumerate(chr_list):\n",
    "        chr_df = df[df['CHR'] == chrom]\n",
    "        ax.scatter(chr_df['cumulative_pos'], chr_df['NEGLOG10P'],\n",
    "                  c=colors[idx % 2], s=5, alpha=0.7, linewidths=0)\n",
    "    \n",
    "    gw_line = -np.log10(GW_SIG)\n",
    "    sugg_line = -np.log10(ANNOTATION_PVAL)\n",
    "    \n",
    "    ax.axhline(y=gw_line, color='red', linestyle='--', linewidth=1.5,\n",
    "               label=f'Genome-wide sig. (P={GW_SIG:.0e})', alpha=0.7)\n",
    "    ax.axhline(y=sugg_line, color='blue', linestyle='--', linewidth=1,\n",
    "               label=f'Suggestive (P={ANNOTATION_PVAL:.0e})', alpha=0.7)\n",
    "    \n",
    "    # Annotate top SNPs\n",
    "    top_snps = df[df['P'] < ANNOTATION_PVAL].copy()\n",
    "    if len(top_snps) > 20:\n",
    "        top_snps = top_snps.nsmallest(20, 'P')\n",
    "    \n",
    "    for _, snp in top_snps.iterrows():\n",
    "        ax.annotate(snp['SNP'],\n",
    "                   xy=(snp['cumulative_pos'], snp['NEGLOG10P']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=7, alpha=0.8)\n",
    "        ax.scatter([snp['cumulative_pos']], [snp['NEGLOG10P']],\n",
    "                  c='red', s=30, marker='D', zorder=5)\n",
    "    \n",
    "    ax.set_xticks(chr_centers)\n",
    "    ax.set_xticklabels([str(c) for c in chr_list])\n",
    "    ax.set_xlabel('Chromosome', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('-log₁₀(P)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Genome-Wide Association Study Results', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- QQ Plot ---\n",
    "    print(\"Generating QQ plot...\")\n",
    "    pvals = df['P'].dropna()\n",
    "    pvals = pvals[pvals > 0]\n",
    "    \n",
    "    observed = -np.log10(sorted(pvals))\n",
    "    n = len(observed)\n",
    "    expected = -np.log10(np.arange(1, n + 1) / (n + 1))\n",
    "    \n",
    "    # Genomic inflation factor\n",
    "    chisq_values = -2 * np.log(pvals)\n",
    "    lambda_gc = np.median(chisq_values) / 0.456\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.scatter(expected, observed, s=10, alpha=0.6, c='#3182bd')\n",
    "    max_val = max(max(expected), max(observed))\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', linewidth=2, alpha=0.7, label='Expected')\n",
    "    ax.text(0.05, 0.95, f'λ = {lambda_gc:.3f}', transform=ax.transAxes, fontsize=11,\n",
    "           verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.set_xlabel('Expected -log₁₀(P)', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Observed -log₁₀(P)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('QQ Plot', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ================================================================\n",
    "    # PREPARE RESULTS\n",
    "    # ================================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GWAS ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get top SNPs list\n",
    "    top_snps_list = []\n",
    "    if len(suggestive) > 0:\n",
    "        for _, row in suggestive.nsmallest(20, 'P').iterrows():\n",
    "            top_snps_list.append({\n",
    "                'snp': row['SNP'],\n",
    "                'chr': int(row['CHR']),\n",
    "                'bp': int(row['BP']),\n",
    "                'p': float(row['P']),\n",
    "                'or': float(row['OR']) if 'OR' in row else None,\n",
    "            })\n",
    "    \n",
    "    # Return summary (NOT raw genotypes)\n",
    "    return {\n",
    "        'status': 'complete',\n",
    "        'total_samples': total_samples,\n",
    "        'cases': cases,\n",
    "        'controls': controls,\n",
    "        'total_snps': total_snps,\n",
    "        'tested_snps': len(df),\n",
    "        'gw_significant_count': len(gw_significant),\n",
    "        'suggestive_count': len(suggestive),\n",
    "        'lambda_gc': float(lambda_gc),\n",
    "        'top_snps': top_snps_list,\n",
    "        'n_pcs': N_PCS,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "## Step 4: Test on Mock Data\n",
    "\n",
    "Run the GWAS pipeline on mock data first to verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gwas_data:\n",
    "    print(\"Testing GWAS pipeline on mock data...\\n\")\n",
    "    print(\"(Note: Mock data is small, so results will be limited)\\n\")\n",
    "    \n",
    "    result = run_gwas_pipeline(gwas_data)\n",
    "    \n",
    "    print(\"\\n=== Mock Result ===\")\n",
    "    if result.public:\n",
    "        r = result.public\n",
    "        print(f\"Status: {r.get('status', 'unknown')}\")\n",
    "        print(f\"Samples: {r.get('total_samples', 'N/A')}\")\n",
    "        print(f\"SNPs tested: {r.get('tested_snps', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "view-mock-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View captured figures\n",
    "if result and result.public_figures:\n",
    "    print(f\"Captured {len(result.public_figures)} figure(s):\")\n",
    "    result.show_figures(\"public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "request-header",
   "metadata": {},
   "source": [
    "## Step 5: Request GWAS on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "request-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    result.request_private()\n",
    "    print(\"\\nGWAS request sent to DO!\")\n",
    "    print(\"Run DO notebook Steps 5-9 now...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitor-header",
   "metadata": {},
   "source": [
    "## Step 6: Monitor GWAS Progress\n",
    "\n",
    "Watch the DO's progress via the live variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for progress variable...\")\n",
    "\n",
    "progress = None\n",
    "for _ in range(60):\n",
    "    peer_vars = session.peer_remote_vars\n",
    "    if \"gwas_progress\" in peer_vars:\n",
    "        progress = peer_vars[\"gwas_progress\"].load(inject=False, auto_accept=True)\n",
    "        print(\"\\nFound gwas_progress!\")\n",
    "        break\n",
    "    time.sleep(1)\n",
    "    print(\".\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GWAS progress\n",
    "if progress:\n",
    "    print(\"\\nMonitoring GWAS progress...\\n\")\n",
    "    print(\"{:^10} {:^20} {:^15}\".format(\"Step\", \"Task\", \"Status\"))\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    last_step = -1\n",
    "    for _ in range(600):  # Monitor for up to 10 minutes\n",
    "        try:\n",
    "            progress = session.peer_remote_vars[\"gwas_progress\"].load(\n",
    "                inject=False, auto_accept=True\n",
    "            )\n",
    "            p = progress.public\n",
    "            \n",
    "            step = p.get(\"step\", 0)\n",
    "            status = p.get(\"status\", \"unknown\")\n",
    "            \n",
    "            if step != last_step or status in [\"complete\", \"starting\"]:\n",
    "                last_step = step\n",
    "                task = p.get(\"current_task\", \"\")\n",
    "                total = p.get(\"total_steps\", \"?\")\n",
    "                \n",
    "                print(\"{:^10} {:^20} {:^15}\".format(\n",
    "                    f\"{step}/{total}\",\n",
    "                    task[:20],\n",
    "                    status\n",
    "                ))\n",
    "                \n",
    "                if status == \"complete\":\n",
    "                    print(\"\\nGWAS analysis complete!\")\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## Step 7: Receive GWAS Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for approved results\n",
    "final_result = bv.wait_for_response(result, timeout=900)  # 15 min timeout\n",
    "\n",
    "if final_result:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GWAS RESULTS RECEIVED!\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    private = final_result.private\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"  Total Samples: {private.get('total_samples', 'N/A')}\")\n",
    "    print(f\"  Cases: {private.get('cases', 'N/A')}\")\n",
    "    print(f\"  Controls: {private.get('controls', 'N/A')}\")\n",
    "    print(f\"  Total SNPs: {private.get('total_snps', 'N/A')}\")\n",
    "    print(f\"  Tested SNPs: {private.get('tested_snps', 'N/A')}\")\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Genome-wide significant: {private.get('gw_significant_count', 0)}\")\n",
    "    print(f\"  Suggestive: {private.get('suggestive_count', 0)}\")\n",
    "    print(f\"  Genomic inflation (λ): {private.get('lambda_gc', 'N/A'):.4f}\")\n",
    "else:\n",
    "    print(\"Timeout waiting for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-top-snps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top SNPs\n",
    "if final_result and final_result.private.get('top_snps'):\n",
    "    print(\"\\n=== Top Significant SNPs ===\")\n",
    "    print(\"{:<15} {:>5} {:>12} {:>12} {:>8}\".format(\"SNP\", \"CHR\", \"BP\", \"P-value\", \"OR\"))\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for snp in final_result.private['top_snps'][:10]:\n",
    "        print(\"{:<15} {:>5} {:>12,} {:>12.2e} {:>8.2f}\".format(\n",
    "            snp['snp'][:15],\n",
    "            snp['chr'],\n",
    "            snp['bp'],\n",
    "            snp['p'],\n",
    "            snp['or'] if snp['or'] else 0\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-real-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GWAS figures from real data\n",
    "if final_result and final_result.private_figures:\n",
    "    print(f\"\\n=== GWAS Plots from REAL Data ({len(final_result.private_figures)} figures) ===\")\n",
    "    final_result.show_figures(\"private\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mock vs real\n",
    "if final_result:\n",
    "    print(\"\\n=== Mock vs Real Comparison ===\")\n",
    "    print(\"{:<25} {:>15} {:>15}\".format(\"\", \"Mock Data\", \"Real Data\"))\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    mock = result.public\n",
    "    real = final_result.private\n",
    "    \n",
    "    print(\"{:<25} {:>15} {:>15}\".format(\n",
    "        \"Samples\",\n",
    "        mock.get('total_samples', 'N/A'),\n",
    "        real.get('total_samples', 'N/A')\n",
    "    ))\n",
    "    print(\"{:<25} {:>15} {:>15}\".format(\n",
    "        \"SNPs Tested\",\n",
    "        mock.get('tested_snps', 'N/A'),\n",
    "        real.get('tested_snps', 'N/A')\n",
    "    ))\n",
    "    print(\"{:<25} {:>15} {:>15}\".format(\n",
    "        \"GW Significant\",\n",
    "        mock.get('gw_significant_count', 0),\n",
    "        real.get('gw_significant_count', 0)\n",
    "    ))\n",
    "    print(\"{:<25} {:>15} {:>15}\".format(\n",
    "        \"Suggestive\",\n",
    "        mock.get('suggestive_count', 0),\n",
    "        real.get('suggestive_count', 0)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed a full privacy-preserving GWAS analysis:\n",
    "\n",
    "1. **Received mock data info** to understand the dataset structure\n",
    "2. **Defined a GWAS pipeline** using PLINK commands\n",
    "3. **Tested locally** on mock data\n",
    "4. **Sent analysis request** to the data owner\n",
    "5. **Monitored progress** via live variables\n",
    "6. **Received results** including plots and significant SNPs\n",
    "\n",
    "### What You Got\n",
    "\n",
    "- Manhattan plot showing association signals\n",
    "- QQ plot with genomic inflation factor\n",
    "- Summary statistics (sample counts, SNP counts)\n",
    "- List of significant/suggestive SNPs with p-values\n",
    "\n",
    "### What You Didn't Get\n",
    "\n",
    "- Raw genotype data (.bed files)\n",
    "- Individual-level genotypes\n",
    "- Full association results for all SNPs\n",
    "\n",
    "### Privacy Preserved!\n",
    "\n",
    "The data owner maintained control over their genomic data while you were able to run a complete GWAS analysis and receive aggregate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
