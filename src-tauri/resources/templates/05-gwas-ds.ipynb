{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Beaver Tutorial 5: GWAS Analysis (Data Scientist)\n",
    "\n",
    "Run a **Genome-Wide Association Study (GWAS)** pipeline with step-by-step approval.\n",
    "\n",
    "Each step returns results for review before proceeding:\n",
    "1. **Merge** - Combine datasets\n",
    "2. **PCA** - Population stratification\n",
    "3. **Association** - Logistic regression\n",
    "4. **Plots** - Manhattan & QQ plots\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install pandas numpy matplotlib -q\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import beaver\n",
    "from beaver import Twin\n",
    "\n",
    "bv = beaver.ctx()\n",
    "session = bv.active_session()\n",
    "session.reset(force=True)\n",
    "\n",
    "print(f\"You: {bv.user}\")\n",
    "print(f\"Peer: {session.peer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "open-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.open()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wait-data-header",
   "metadata": {},
   "source": [
    "## Step 2: Wait for GWAS Data\n",
    "\n",
    "**Run DO notebook first!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-data",
   "metadata": {},
   "outputs": [],
   "source": "gwas_data = session.wait_for_remote_var(\"gwas_data\", timeout=120, trust_loader=True)\nif gwas_data:\n    print(f\"Mock info: {gwas_data.public['n_samples_1']} samples, {gwas_data.public['n_variants_1']} variants\")\nelse:\n    print(\"Timeout - run DO notebook first!\")"
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## GWAS Step 1: Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bv\n",
    "def gwas_step1_merge(data: dict) -> dict:\n",
    "    \"\"\"Merge two PLINK datasets.\"\"\"\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"STEP 1: MERGE DATASETS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    DATASET1 = data['dataset1_prefix']\n",
    "    DATASET2 = data['dataset2_prefix']\n",
    "    WORKDIR = Path(tempfile.mkdtemp(prefix=\"gwas_\"))\n",
    "    COMBINED = WORKDIR / \"combined\"\n",
    "    \n",
    "    print(f\"Dataset 1: {data['dataset1_name']}\")\n",
    "    print(f\"Dataset 2: {data['dataset2_name']}\")\n",
    "    \n",
    "    def run_plink(args):\n",
    "        cmd = [\"plink\"] + args\n",
    "        print(f\">> {' '.join(cmd[:5])}...\")\n",
    "        proc = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        return proc.returncode\n",
    "    \n",
    "    # Try merge\n",
    "    ret = run_plink([\"--bfile\", DATASET1, \"--bmerge\", DATASET2, \"--out\", str(COMBINED)])\n",
    "    \n",
    "    # Handle strand flips\n",
    "    missnp = Path(f\"{COMBINED}-merge.missnp\")\n",
    "    if ret != 0 and missnp.exists():\n",
    "        print(\"Strand issues found, flipping...\")\n",
    "        flipped = f\"{DATASET2}_flipped\"\n",
    "        run_plink([\"--bfile\", DATASET2, \"--flip\", str(missnp), \"--make-bed\", \"--out\", flipped])\n",
    "        run_plink([\"--bfile\", DATASET1, \"--bmerge\", flipped, \"--out\", str(COMBINED)])\n",
    "    \n",
    "    # Count samples/variants\n",
    "    fam_path = Path(f\"{COMBINED}.fam\")\n",
    "    bim_path = Path(f\"{COMBINED}.bim\")\n",
    "    \n",
    "    n_samples = sum(1 for _ in open(fam_path))\n",
    "    n_variants = sum(1 for _ in open(bim_path))\n",
    "    \n",
    "    # Count cases/controls\n",
    "    cases, controls = 0, 0\n",
    "    for line in open(fam_path):\n",
    "        pheno = line.split()[5]\n",
    "        if pheno == \"2\": cases += 1\n",
    "        elif pheno == \"1\": controls += 1\n",
    "    \n",
    "    print(f\"\\nMerged: {n_samples} samples, {n_variants} variants\")\n",
    "    print(f\"Cases: {cases}, Controls: {controls}\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'merged',\n",
    "        'combined_prefix': str(COMBINED),\n",
    "        'workdir': str(WORKDIR),\n",
    "        'n_samples': n_samples,\n",
    "        'n_variants': n_variants,\n",
    "        'cases': cases,\n",
    "        'controls': controls,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on mock, then request real\n",
    "merge_result = gwas_step1_merge(gwas_data)\n",
    "print(f\"\\nMock result: {merge_result.public}\")\n",
    "\n",
    "merge_result.request_private()\n",
    "print(\"\\nMerge request sent! Waiting for DO to approve...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-merge",
   "metadata": {},
   "outputs": [],
   "source": "# Wait for merge results (summary only!)\nmerge_approved = bv.wait_for_response(merge_result, timeout=300)\n\nif merge_approved and merge_approved.private:\n    r = merge_approved.private\n    print(f\"DO approved merge!\")\n    print(f\"  Summary: {r.get('n_samples', 'N/A')} samples, {r.get('n_variants', 'N/A')} variants\")\n    print(f\"  Cases: {r.get('cases', 'N/A')}, Controls: {r.get('controls', 'N/A')}\")\n\n# Wait for DO to publish pca_input Twin with real merge paths\nprint(\"\\n⏳ Waiting for DO to publish pca_input...\")\npca_input = session.wait_for_remote_var(\"pca_input\", timeout=120, trust_loader=True)\nif pca_input:\n    print(f\"✓ Loaded pca_input from DO\")\nelse:\n    print(\"Timeout waiting for pca_input\")"
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## GWAS Step 2: PCA for Population Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-pca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bv\n",
    "def gwas_step2_pca(data: dict) -> dict:\n",
    "    \"\"\"Run PCA for population stratification.\"\"\"\n",
    "    import subprocess\n",
    "    from pathlib import Path\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"STEP 2: PCA\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    COMBINED = data['combined_prefix']\n",
    "    WORKDIR = Path(data['workdir'])\n",
    "    N_PCS = 10\n",
    "    \n",
    "    def run_plink(args):\n",
    "        cmd = [\"plink\"] + args\n",
    "        print(f\">> {' '.join(cmd[:5])}...\")\n",
    "        subprocess.run(cmd, capture_output=True)\n",
    "    \n",
    "    # LD pruning\n",
    "    print(\"LD pruning...\")\n",
    "    run_plink([\"--bfile\", COMBINED, \"--indep-pairwise\", \"50\", \"5\", \"0.2\", \"--out\", f\"{COMBINED}_pruned\"])\n",
    "    run_plink([\"--bfile\", COMBINED, \"--extract\", f\"{COMBINED}_pruned.prune.in\", \"--make-bed\", \"--out\", f\"{COMBINED}_pruned_data\"])\n",
    "    \n",
    "    # Remove ambiguous SNPs\n",
    "    atgc = WORKDIR / \"atgc.txt\"\n",
    "    with open(f\"{COMBINED}_pruned_data.bim\") as f, open(atgc, \"w\") as out:\n",
    "        for line in f:\n",
    "            fields = line.split()\n",
    "            a1, a2 = fields[4], fields[5]\n",
    "            if (a1, a2) in [(\"A\",\"T\"),(\"T\",\"A\"),(\"C\",\"G\"),(\"G\",\"C\")]:\n",
    "                out.write(fields[1] + \"\\n\")\n",
    "    \n",
    "    run_plink([\"--bfile\", f\"{COMBINED}_pruned_data\", \"--exclude\", str(atgc), \"--make-bed\", \"--out\", f\"{COMBINED}_noambig\"])\n",
    "    \n",
    "    # Run PCA\n",
    "    print(f\"Computing {N_PCS} PCs...\")\n",
    "    run_plink([\"--bfile\", f\"{COMBINED}_noambig\", \"--pca\", str(N_PCS), \"--out\", f\"{COMBINED}_pca\"])\n",
    "    \n",
    "    # Add header to eigenvec\n",
    "    eigenvec = Path(f\"{COMBINED}_pca.eigenvec\")\n",
    "    header = \" \".join([\"FID\", \"IID\"] + [f\"PC{i}\" for i in range(1, N_PCS+1)]) + \"\\n\"\n",
    "    content = eigenvec.read_text()\n",
    "    eigenvec.write_text(header + content)\n",
    "    \n",
    "    # Plot PCA\n",
    "    print(\"Generating PCA plot...\")\n",
    "    df = pd.read_csv(eigenvec, sep=r\"\\s+\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(df['PC1'], df['PC2'], alpha=0.6, s=20)\n",
    "    ax.set_xlabel('PC1', fontsize=12)\n",
    "    ax.set_ylabel('PC2', fontsize=12)\n",
    "    ax.set_title('Population Structure (PCA)', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"PCA complete!\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'pca_complete',\n",
    "        'combined_prefix': COMBINED,\n",
    "        'workdir': str(WORKDIR),\n",
    "        'eigenvec_path': str(eigenvec),\n",
    "        'n_pcs': N_PCS,\n",
    "        'n_samples': len(df),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-pca",
   "metadata": {},
   "outputs": [],
   "source": "# Run PCA on mock data using pca_input Twin from DO\n# The public side has mock paths that work locally\npca_result = gwas_step2_pca(pca_input)\nprint(f\"\\nMock PCA complete\")\npca_result.show_figures(\"public\")\n\npca_result.request_private()\nprint(\"\\nPCA request sent! Waiting for DO to approve...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-pca",
   "metadata": {},
   "outputs": [],
   "source": "# Wait for PCA results (summary + plot only!)\npca_approved = bv.wait_for_response(pca_result, timeout=300)\n\nif pca_approved and pca_approved.private:\n    r = pca_approved.private\n    print(f\"DO approved PCA!\")\n    print(f\"  Summary: {r.get('n_pcs', 'N/A')} PCs for {r.get('n_samples', 'N/A')} samples\")\n    print(\"\\nPCA Plot from REAL data:\")\n    pca_approved.show_figures(\"private\")\n\n# Wait for DO to publish assoc_input Twin\nprint(\"\\n⏳ Waiting for DO to publish assoc_input...\")\nassoc_input = session.wait_for_remote_var(\"assoc_input\", timeout=120, trust_loader=True)\nif assoc_input:\n    print(f\"✓ Loaded assoc_input from DO\")\nelse:\n    print(\"Timeout waiting for assoc_input\")"
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## GWAS Step 3: Association Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-assoc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bv\n",
    "def gwas_step3_association(data: dict) -> dict:\n",
    "    \"\"\"Run logistic regression with PCA covariates.\"\"\"\n",
    "    import subprocess\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"STEP 3: ASSOCIATION TESTING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    COMBINED = data['combined_prefix']\n",
    "    eigenvec = data['eigenvec_path']\n",
    "    N_PCS = data['n_pcs']\n",
    "    \n",
    "    covar_names = \",\".join([f\"PC{i}\" for i in range(1, N_PCS+1)])\n",
    "    \n",
    "    print(\"Running logistic regression...\")\n",
    "    cmd = [\"plink\", \"--bfile\", COMBINED, \"--logistic\", \"hide-covar\",\n",
    "           \"--covar\", eigenvec, \"--covar-name\", covar_names,\n",
    "           \"--ci\", \"0.95\", \"--out\", f\"{COMBINED}_gwas\"]\n",
    "    print(f\">> {' '.join(cmd[:6])}...\")\n",
    "    subprocess.run(cmd, capture_output=True)\n",
    "    \n",
    "    # Load results\n",
    "    results_file = f\"{COMBINED}_gwas.assoc.logistic\"\n",
    "    df = pd.read_csv(results_file, sep=r\"\\s+\")\n",
    "    df = df[df['P'].notna()]\n",
    "    df['P'] = pd.to_numeric(df['P'], errors='coerce')\n",
    "    df = df.dropna(subset=['P'])\n",
    "    df = df[(df['P'] > 0) & (df['P'] <= 1)]\n",
    "    \n",
    "    # Count significant\n",
    "    gw_sig = len(df[df['P'] < 5e-8])\n",
    "    suggestive = len(df[df['P'] < 1e-5])\n",
    "    \n",
    "    # Genomic inflation\n",
    "    chisq = -2 * np.log(df['P'])\n",
    "    lambda_gc = np.median(chisq) / 0.456\n",
    "    \n",
    "    print(f\"\\nTested: {len(df)} SNPs\")\n",
    "    print(f\"Genome-wide significant (P < 5e-8): {gw_sig}\")\n",
    "    print(f\"Suggestive (P < 1e-5): {suggestive}\")\n",
    "    print(f\"Genomic inflation λ: {lambda_gc:.3f}\")\n",
    "    \n",
    "    # Top SNPs\n",
    "    top_snps = []\n",
    "    for _, row in df.nsmallest(20, 'P').iterrows():\n",
    "        top_snps.append({\n",
    "            'snp': row['SNP'],\n",
    "            'chr': int(row['CHR']) if pd.notna(row['CHR']) else 0,\n",
    "            'bp': int(row['BP']) if pd.notna(row['BP']) else 0,\n",
    "            'p': float(row['P']),\n",
    "            'or': float(row['OR']) if 'OR' in row and pd.notna(row['OR']) else None,\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'status': 'association_complete',\n",
    "        'combined_prefix': COMBINED,\n",
    "        'results_file': results_file,\n",
    "        'tested_snps': len(df),\n",
    "        'gw_significant': gw_sig,\n",
    "        'suggestive': suggestive,\n",
    "        'lambda_gc': float(lambda_gc),\n",
    "        'top_snps': top_snps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-assoc",
   "metadata": {},
   "outputs": [],
   "source": "# Run association on mock data using assoc_input Twin from DO\nassoc_result = gwas_step3_association(assoc_input)\nprint(f\"\\nMock association: {assoc_result.public.get('tested_snps', 0)} SNPs tested\")\n\nassoc_result.request_private()\nprint(\"\\nAssociation request sent! Waiting for DO to approve...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-assoc",
   "metadata": {},
   "outputs": [],
   "source": "# Wait for association results (summary + top SNPs only!)\nassoc_approved = bv.wait_for_response(assoc_result, timeout=600)\n\nif assoc_approved and assoc_approved.private:\n    r = assoc_approved.private\n    print(f\"DO approved association!\")\n    print(f\"  Tested: {r.get('tested_snps', 'N/A')} SNPs\")\n    print(f\"  GW significant: {r.get('gw_significant', 'N/A')}\")\n    print(f\"  Suggestive: {r.get('suggestive', 'N/A')}\")\n    print(f\"  Lambda: {r.get('lambda_gc', 0):.3f}\")\n    \n    top_snps = r.get('top_snps', [])\n    if top_snps:\n        print(f\"\\nTop SNPs from REAL data:\")\n        for snp in top_snps[:5]:\n            print(f\"  {snp['snp']}: P={snp['p']:.2e}\")\n\n# Wait for DO to publish plots_input Twin\nprint(\"\\n⏳ Waiting for DO to publish plots_input...\")\nplots_input = session.wait_for_remote_var(\"plots_input\", timeout=120, trust_loader=True)\nif plots_input:\n    print(f\"✓ Loaded plots_input from DO\")\nelse:\n    print(\"Timeout waiting for plots_input\")"
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## GWAS Step 4: Generate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bv\n",
    "def gwas_step4_plots(data: dict) -> dict:\n",
    "    \"\"\"Generate Manhattan and QQ plots.\"\"\"\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"STEP 4: GENERATE PLOTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    results_file = data['results_file']\n",
    "    \n",
    "    # Load results\n",
    "    df = pd.read_csv(results_file, sep=r\"\\s+\")\n",
    "    df = df[df['P'].notna()]\n",
    "    df['P'] = pd.to_numeric(df['P'], errors='coerce')\n",
    "    df = df.dropna(subset=['P'])\n",
    "    df = df[(df['P'] > 0) & (df['P'] <= 1)]\n",
    "    df['NEGLOG10P'] = -np.log10(df['P'])\n",
    "    df = df[np.isfinite(df['NEGLOG10P'])]\n",
    "    \n",
    "    # Clean chromosomes\n",
    "    df['CHR'] = df['CHR'].replace({'X': 23, 'Y': 24, 'MT': 25})\n",
    "    df['CHR'] = pd.to_numeric(df['CHR'], errors='coerce')\n",
    "    df = df.dropna(subset=['CHR', 'BP'])\n",
    "    df['CHR'] = df['CHR'].astype(int)\n",
    "    df['BP'] = df['BP'].astype(int)\n",
    "    df = df.sort_values(['CHR', 'BP']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Plotting {len(df)} SNPs...\")\n",
    "    \n",
    "    # --- Manhattan Plot ---\n",
    "    print(\"Creating Manhattan plot...\")\n",
    "    \n",
    "    df['cumpos'] = 0\n",
    "    chr_centers = []\n",
    "    last_pos = 0\n",
    "    for chrom in sorted(df['CHR'].unique()):\n",
    "        chr_df = df[df['CHR'] == chrom]\n",
    "        chr_len = chr_df['BP'].max()\n",
    "        df.loc[df['CHR'] == chrom, 'cumpos'] = chr_df['BP'] + last_pos\n",
    "        chr_centers.append(last_pos + chr_len / 2)\n",
    "        last_pos += chr_len\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    colors = ['#3182bd', '#9ecae1']\n",
    "    chr_list = sorted(df['CHR'].unique())\n",
    "    \n",
    "    for idx, chrom in enumerate(chr_list):\n",
    "        chr_df = df[df['CHR'] == chrom]\n",
    "        ax.scatter(chr_df['cumpos'], chr_df['NEGLOG10P'],\n",
    "                  c=colors[idx % 2], s=3, alpha=0.6)\n",
    "    \n",
    "    ax.axhline(y=-np.log10(5e-8), color='red', linestyle='--', lw=1.5, label='GW sig (5e-8)')\n",
    "    ax.axhline(y=-np.log10(1e-5), color='blue', linestyle='--', lw=1, label='Suggestive (1e-5)')\n",
    "    \n",
    "    # Annotate top hits\n",
    "    top = df[df['P'] < 1e-5].nsmallest(10, 'P')\n",
    "    for _, snp in top.iterrows():\n",
    "        ax.annotate(snp['SNP'], (snp['cumpos'], snp['NEGLOG10P']),\n",
    "                   fontsize=7, alpha=0.8, xytext=(3, 3), textcoords='offset points')\n",
    "        ax.scatter([snp['cumpos']], [snp['NEGLOG10P']], c='red', s=25, marker='D', zorder=5)\n",
    "    \n",
    "    ax.set_xticks(chr_centers)\n",
    "    ax.set_xticklabels([str(c) for c in chr_list])\n",
    "    ax.set_xlabel('Chromosome')\n",
    "    ax.set_ylabel('-log₁₀(P)')\n",
    "    ax.set_title('Manhattan Plot')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- QQ Plot ---\n",
    "    print(\"Creating QQ plot...\")\n",
    "    \n",
    "    pvals = df['P'].dropna()\n",
    "    pvals = pvals[pvals > 0]\n",
    "    observed = -np.log10(sorted(pvals))\n",
    "    n = len(observed)\n",
    "    expected = -np.log10(np.arange(1, n + 1) / (n + 1))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.scatter(expected, observed, s=8, alpha=0.5, c='#3182bd')\n",
    "    max_val = max(max(expected), max(observed))\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', lw=2, label='Expected')\n",
    "    \n",
    "    lambda_gc = data.get('lambda_gc', 0)\n",
    "    ax.text(0.05, 0.95, f'λ = {lambda_gc:.3f}', transform=ax.transAxes,\n",
    "           fontsize=11, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlabel('Expected -log₁₀(P)')\n",
    "    ax.set_ylabel('Observed -log₁₀(P)')\n",
    "    ax.set_title('QQ Plot')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Plots complete!\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'plots_complete',\n",
    "        'n_snps_plotted': len(df),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-plots",
   "metadata": {},
   "outputs": [],
   "source": "# Run plots on mock data using plots_input Twin from DO\nplots_result = gwas_step4_plots(plots_input)\nprint(f\"\\nMock plots:\")\nplots_result.show_figures(\"public\")\n\nplots_result.request_private()\nprint(\"\\nPlots request sent! Waiting for DO to approve...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for plots\n",
    "plots_approved = bv.wait_for_response(plots_result, timeout=300)\n",
    "\n",
    "if plots_approved:\n",
    "    print(\"GWAS plots received!\")\n",
    "    print(f\"\\n=== Manhattan & QQ Plots from REAL Data ===\")\n",
    "    plots_approved.show_figures(\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "You ran a complete GWAS in 4 steps:\n",
    "\n",
    "1. **Merge** - Combined datasets, got sample/variant counts\n",
    "2. **PCA** - Population stratification, saw PCA plot\n",
    "3. **Association** - Logistic regression, got top SNPs\n",
    "4. **Plots** - Manhattan & QQ plots\n",
    "\n",
    "### Privacy Preserved!\n",
    "\n",
    "- You received **summary statistics** and **plots**\n",
    "- You did NOT receive raw genotype data\n",
    "- DO approved each step before proceeding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}